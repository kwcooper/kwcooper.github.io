190116

I've recently discovered the value in web scraping tools after working on a congressional voting project. 

wget is the typical commandline go to, however, I think it's limited inwhat most useage really needs. On the other end of the spectrum, using python, there is beautifulsoup, but that may have too many bells and whistles for most mundane tasks. Enter the requests package with python. This extendeds wget like functionality. 

Grab it with `pip install requests`, import it, and call the url with r`requests.get(*url*)`

Grab 404 errors by taking the output, say r, and `r.status_code`

